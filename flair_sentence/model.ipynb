{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"phase2_baby_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am primarily breastfeeding but I thought thi...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1114646400B000056OUGA3FFDK09UJS1TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I discovered Medela Microwave Steam Cleaning B...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1114646400B000056OUGA3FFDK09UJS1TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I feel badly for the waste of money but the ba...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1114646400B000056OUGA3FFDK09UJS1TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>And not space consuming.</td>\n",
       "      <td>pos</td>\n",
       "      <td>1114646400B000056OUGA3FFDK09UJS1TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Plus you can use them during travel at the off...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1114646400B000056OUGA3FFDK09UJS1TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Much more cost efficient and useful!</td>\n",
       "      <td>pos</td>\n",
       "      <td>1114646400B000056OUGA3FFDK09UJS1TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>This monitor is decent for the price I guess.</td>\n",
       "      <td>pos</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>But I think I would have rather spent a little...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>The pro to the monitor is that it picks up the...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>But the problem is that there's so much static...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>There's so much static that it almost complete...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>If you run the monitor on just the batteries a...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>The only problem with that is that the battery...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>So if you have the money to spend on a new 9V ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>But if you have that kind of money I would sug...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>I think I am going to return this for somethin...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm very disappointed in Fisher Price.</td>\n",
       "      <td>pos</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>They usually have such great quality products.</td>\n",
       "      <td>neg</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>I can't believe they would come out with somet...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>My suggestion.</td>\n",
       "      <td>neg</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>don't [spend] your money on this monitor.</td>\n",
       "      <td>neu</td>\n",
       "      <td>1049587200B00005TNIHA1B23P1EVL3EGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a wonderful gate when you have your ha...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1128038400B000058CC7A3I9J4BE0ZSTL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>We've used gates for years with our pets and t...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1128038400B000058CC7A3I9J4BE0ZSTL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>We actually went out and bought a second gate ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1128038400B000058CC7A3I9J4BE0ZSTL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a great large bib that is colorful and...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1213920000B000H3YFSIA32CWXI683CS3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>Some bibs are thin but this has a thickness to...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1213920000B000H3YFSIA32CWXI683CS3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>The teether on it is a bonus!</td>\n",
       "      <td>pos</td>\n",
       "      <td>1213920000B000H3YFSIA32CWXI683CS3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>It's been 5 months aleady and we've had no tro...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1030060800B00004D3EUA3IU7IR378D2NI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>It leaked the first time we used it because I ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1030060800B00004D3EUA3IU7IR378D2NI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>My boys are quite big for their age and they l...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1030060800B00004D3EUA3IU7IR378D2NI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15624</th>\n",
       "      <td>9</td>\n",
       "      <td>I was disappointed that it looks like one piec...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1215475200B0013FGWD0APJ29ZG66KWX2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15625</th>\n",
       "      <td>9</td>\n",
       "      <td>I ended up buying a new bumper and using this ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1215475200B0013FGWD0APJ29ZG66KWX2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15626</th>\n",
       "      <td>9</td>\n",
       "      <td>I would have returned it if it weren't for the...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1215475200B0013FGWD0APJ29ZG66KWX2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15627</th>\n",
       "      <td>9</td>\n",
       "      <td>As for the breathability - the mesh seems to b...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1215475200B0013FGWD0APJ29ZG66KWX2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15628</th>\n",
       "      <td>9</td>\n",
       "      <td>The fit was somewhat loose on my crib and hard...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1215475200B0013FGWD0APJ29ZG66KWX2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15629</th>\n",
       "      <td>9</td>\n",
       "      <td>I am not terribly impressed - I wish it was ti...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1215475200B0013FGWD0APJ29ZG66KWX2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630</th>\n",
       "      <td>9</td>\n",
       "      <td>I received this off my baby shower registry.</td>\n",
       "      <td>neg</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15631</th>\n",
       "      <td>9</td>\n",
       "      <td>Luckily,  we we're over some really cushy carpet.</td>\n",
       "      <td>pos</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15632</th>\n",
       "      <td>9</td>\n",
       "      <td>The right latch (when facing forward) did NOT ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15633</th>\n",
       "      <td>9</td>\n",
       "      <td>My daughter fell out the right leg side,  and ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15634</th>\n",
       "      <td>9</td>\n",
       "      <td>If you own this,  CHECK the strength of the le...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15635</th>\n",
       "      <td>9</td>\n",
       "      <td>PLEASE just spend the extra dollar to get a ca...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15636</th>\n",
       "      <td>9</td>\n",
       "      <td>This thing kind of just slide latches into pla...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15637</th>\n",
       "      <td>9</td>\n",
       "      <td>Please,  please,  please - invest in another o...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15638</th>\n",
       "      <td>9</td>\n",
       "      <td>I really can't stress this.</td>\n",
       "      <td>neu</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15639</th>\n",
       "      <td>9</td>\n",
       "      <td>Just check the strength,  please?</td>\n",
       "      <td>neg</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15640</th>\n",
       "      <td>9</td>\n",
       "      <td>I don't want to read any other reviews besides...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15641</th>\n",
       "      <td>9</td>\n",
       "      <td>You'll be able to tell if its faulty by just c...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15642</th>\n",
       "      <td>9</td>\n",
       "      <td>If they're both loose.. Than geez I don't know.</td>\n",
       "      <td>neg</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643</th>\n",
       "      <td>9</td>\n",
       "      <td>Good luck.</td>\n",
       "      <td>neg</td>\n",
       "      <td>1203638400B0002XO5M4A1HCSAQPP45PM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15644</th>\n",
       "      <td>9</td>\n",
       "      <td>The mixer seems very handy but I could not use...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1257465600B00005BYUJA3687F2I2G6U8H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15645</th>\n",
       "      <td>9</td>\n",
       "      <td>Brown's 8-ounce bottles (regular width,  not s...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1257465600B00005BYUJA3687F2I2G6U8H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15646</th>\n",
       "      <td>9</td>\n",
       "      <td>While my daughter liked this,  the lights brok...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1253836800B0008JIL3GA37QPG0KDU5UPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15647</th>\n",
       "      <td>9</td>\n",
       "      <td>It is very poor quality and I would never buy ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1253836800B0008JIL3GA37QPG0KDU5UPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15648</th>\n",
       "      <td>9</td>\n",
       "      <td>I'm not satisfied with Madela pump in style!</td>\n",
       "      <td>neu</td>\n",
       "      <td>1118102400B00065H55WA3CHKT5JI3XIFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15649</th>\n",
       "      <td>9</td>\n",
       "      <td>It's very expensive but it doesn't work well, ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1118102400B00065H55WA3CHKT5JI3XIFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15650</th>\n",
       "      <td>9</td>\n",
       "      <td>I don't like it at all... I called madela and ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1118102400B00065H55WA3CHKT5JI3XIFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15651</th>\n",
       "      <td>9</td>\n",
       "      <td>What a peace of junk!!!</td>\n",
       "      <td>neu</td>\n",
       "      <td>1118102400B00065H55WA3CHKT5JI3XIFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15652</th>\n",
       "      <td>9</td>\n",
       "      <td>The handles on this thing are BPA (illegal in ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1209686400B000JOOGR0A2XZ7OFHNNKOQU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15653</th>\n",
       "      <td>9</td>\n",
       "      <td>I have no idea why it's in the Amazon BPA-free...</td>\n",
       "      <td>neu</td>\n",
       "      <td>1209686400B000JOOGR0A2XZ7OFHNNKOQU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15654 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       group_id                                           sentence sentiment  \\\n",
       "0             1  I am primarily breastfeeding but I thought thi...       neg   \n",
       "1             1  I discovered Medela Microwave Steam Cleaning B...       neu   \n",
       "2             1  I feel badly for the waste of money but the ba...       neu   \n",
       "3             1                           And not space consuming.       pos   \n",
       "4             1  Plus you can use them during travel at the off...       pos   \n",
       "5             1               Much more cost efficient and useful!       pos   \n",
       "6             1      This monitor is decent for the price I guess.       pos   \n",
       "7             1  But I think I would have rather spent a little...       neg   \n",
       "8             1  The pro to the monitor is that it picks up the...       pos   \n",
       "9             1  But the problem is that there's so much static...       neg   \n",
       "10            1  There's so much static that it almost complete...       pos   \n",
       "11            1  If you run the monitor on just the batteries a...       neg   \n",
       "12            1  The only problem with that is that the battery...       neu   \n",
       "13            1  So if you have the money to spend on a new 9V ...       neg   \n",
       "14            1  But if you have that kind of money I would sug...       neg   \n",
       "15            1  I think I am going to return this for somethin...       neg   \n",
       "16            1             I'm very disappointed in Fisher Price.       pos   \n",
       "17            1     They usually have such great quality products.       neg   \n",
       "18            1  I can't believe they would come out with somet...       neu   \n",
       "19            1                                     My suggestion.       neg   \n",
       "20            1          don't [spend] your money on this monitor.       neu   \n",
       "21            1  This is a wonderful gate when you have your ha...       pos   \n",
       "22            1  We've used gates for years with our pets and t...       pos   \n",
       "23            1  We actually went out and bought a second gate ...       pos   \n",
       "24            1  This is a great large bib that is colorful and...       pos   \n",
       "25            1  Some bibs are thin but this has a thickness to...       neu   \n",
       "26            1                      The teether on it is a bonus!       pos   \n",
       "27            1  It's been 5 months aleady and we've had no tro...       pos   \n",
       "28            1  It leaked the first time we used it because I ...       neu   \n",
       "29            1  My boys are quite big for their age and they l...       neu   \n",
       "...         ...                                                ...       ...   \n",
       "15624         9  I was disappointed that it looks like one piec...       neu   \n",
       "15625         9  I ended up buying a new bumper and using this ...       neg   \n",
       "15626         9  I would have returned it if it weren't for the...       neu   \n",
       "15627         9  As for the breathability - the mesh seems to b...       neg   \n",
       "15628         9  The fit was somewhat loose on my crib and hard...       neu   \n",
       "15629         9  I am not terribly impressed - I wish it was ti...       neu   \n",
       "15630         9       I received this off my baby shower registry.       neg   \n",
       "15631         9  Luckily,  we we're over some really cushy carpet.       pos   \n",
       "15632         9  The right latch (when facing forward) did NOT ...       neu   \n",
       "15633         9  My daughter fell out the right leg side,  and ...       pos   \n",
       "15634         9  If you own this,  CHECK the strength of the le...       neg   \n",
       "15635         9  PLEASE just spend the extra dollar to get a ca...       neu   \n",
       "15636         9  This thing kind of just slide latches into pla...       neu   \n",
       "15637         9  Please,  please,  please - invest in another o...       neu   \n",
       "15638         9                        I really can't stress this.       neu   \n",
       "15639         9                  Just check the strength,  please?       neg   \n",
       "15640         9  I don't want to read any other reviews besides...       neg   \n",
       "15641         9  You'll be able to tell if its faulty by just c...       neg   \n",
       "15642         9    If they're both loose.. Than geez I don't know.       neg   \n",
       "15643         9                                         Good luck.       neg   \n",
       "15644         9  The mixer seems very handy but I could not use...       neu   \n",
       "15645         9  Brown's 8-ounce bottles (regular width,  not s...       neg   \n",
       "15646         9  While my daughter liked this,  the lights brok...       pos   \n",
       "15647         9  It is very poor quality and I would never buy ...       neu   \n",
       "15648         9       I'm not satisfied with Madela pump in style!       neu   \n",
       "15649         9  It's very expensive but it doesn't work well, ...       neu   \n",
       "15650         9  I don't like it at all... I called madela and ...       neu   \n",
       "15651         9                            What a peace of junk!!!       neu   \n",
       "15652         9  The handles on this thing are BPA (illegal in ...       neg   \n",
       "15653         9  I have no idea why it's in the Amazon BPA-free...       neu   \n",
       "\n",
       "                                     uuid  \n",
       "0      1114646400B000056OUGA3FFDK09UJS1TD  \n",
       "1      1114646400B000056OUGA3FFDK09UJS1TD  \n",
       "2      1114646400B000056OUGA3FFDK09UJS1TD  \n",
       "3      1114646400B000056OUGA3FFDK09UJS1TD  \n",
       "4      1114646400B000056OUGA3FFDK09UJS1TD  \n",
       "5      1114646400B000056OUGA3FFDK09UJS1TD  \n",
       "6      1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "7      1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "8      1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "9      1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "10     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "11     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "12     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "13     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "14     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "15     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "16     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "17     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "18     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "19     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "20     1049587200B00005TNIHA1B23P1EVL3EGI  \n",
       "21     1128038400B000058CC7A3I9J4BE0ZSTL5  \n",
       "22     1128038400B000058CC7A3I9J4BE0ZSTL5  \n",
       "23     1128038400B000058CC7A3I9J4BE0ZSTL5  \n",
       "24     1213920000B000H3YFSIA32CWXI683CS3M  \n",
       "25     1213920000B000H3YFSIA32CWXI683CS3M  \n",
       "26     1213920000B000H3YFSIA32CWXI683CS3M  \n",
       "27     1030060800B00004D3EUA3IU7IR378D2NI  \n",
       "28     1030060800B00004D3EUA3IU7IR378D2NI  \n",
       "29     1030060800B00004D3EUA3IU7IR378D2NI  \n",
       "...                                   ...  \n",
       "15624   1215475200B0013FGWD0APJ29ZG66KWX2  \n",
       "15625   1215475200B0013FGWD0APJ29ZG66KWX2  \n",
       "15626   1215475200B0013FGWD0APJ29ZG66KWX2  \n",
       "15627   1215475200B0013FGWD0APJ29ZG66KWX2  \n",
       "15628   1215475200B0013FGWD0APJ29ZG66KWX2  \n",
       "15629   1215475200B0013FGWD0APJ29ZG66KWX2  \n",
       "15630  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15631  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15632  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15633  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15634  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15635  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15636  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15637  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15638  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15639  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15640  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15641  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15642  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15643  1203638400B0002XO5M4A1HCSAQPP45PM4  \n",
       "15644  1257465600B00005BYUJA3687F2I2G6U8H  \n",
       "15645  1257465600B00005BYUJA3687F2I2G6U8H  \n",
       "15646  1253836800B0008JIL3GA37QPG0KDU5UPE  \n",
       "15647  1253836800B0008JIL3GA37QPG0KDU5UPE  \n",
       "15648  1118102400B00065H55WA3CHKT5JI3XIFL  \n",
       "15649  1118102400B00065H55WA3CHKT5JI3XIFL  \n",
       "15650  1118102400B00065H55WA3CHKT5JI3XIFL  \n",
       "15651  1118102400B00065H55WA3CHKT5JI3XIFL  \n",
       "15652  1209686400B000JOOGR0A2XZ7OFHNNKOQU  \n",
       "15653  1209686400B000JOOGR0A2XZ7OFHNNKOQU  \n",
       "\n",
       "[15654 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['sentiment', 'sentence']].rename(columns={\"sentiment\":\"label\", \"sentence\":\"text\"})\n",
    " \n",
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-10 09:04:55,767 Reading data from .\n",
      "2019-05-10 09:04:55,769 Train: train.csv\n",
      "2019-05-10 09:04:55,770 Dev: dev.csv\n",
      "2019-05-10 09:04:55,771 Test: test.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path(''), test_file = 'test.csv', dev_file = 'dev.csv', train_file = 'train.csv')#.downsample(0.01)\n",
    "\n",
    "word_embeddings = [WordEmbeddings('glove'), \n",
    "                   FlairEmbeddings('news-forward-fast', use_cache = True), \n",
    "                   FlairEmbeddings('news-backward-fast', use_cache = True)]\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, \n",
    "                                            hidden_size = 16, \n",
    "                                            reproject_words = True, \n",
    "                                            reproject_words_dimension = 256)\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary = corpus.make_label_dictionary(), multi_label = False)\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-10 09:03:32,332 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-10 09:03:32,333 Evaluation method: MICRO_F1_SCORE\n",
      "2019-05-10 09:03:32,335 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-10 09:03:34,957 epoch 1 - iter 0/392 - loss 0.04563719\n",
      "2019-05-10 09:04:27,153 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-10 09:04:27,154 Exiting from training early.\n",
      "2019-05-10 09:04:27,155 Saving model ...\n",
      "2019-05-10 09:04:30,378 Done.\n",
      "2019-05-10 09:04:30,383 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-10 09:04:30,384 Testing using best model ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-78f734cdf7b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, evaluation_metric, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, anneal_against_train_loss, train_with_dev, monitor_train, embeddings_in_memory, checkpoint, save_final_model, anneal_with_restarts, test_mode, param_selection_mode, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# test best model if test data is present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_in_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mfinal_test\u001b[0;34m(self, base_path, embeddings_in_memory, evaluation_metric, eval_mini_batch_size)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         test_metric, test_loss = self.evaluate(self.model, self.corpus.test, eval_mini_batch_size=eval_mini_batch_size,\n\u001b[0;32m--> 278\u001b[0;31m                                                embeddings_in_memory=embeddings_in_memory)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MICRO_AVG: acc {test_metric.micro_avg_accuracy()} - f1-score {test_metric.micro_avg_f_score()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_set, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             return ModelTrainer._evaluate_text_classifier(model, data_set, eval_mini_batch_size, embeddings_in_memory,\n\u001b[0;32m--> 343\u001b[0;31m                                                           out_path)\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             return ModelTrainer._evaluate_sequence_tagger(model, data_set, eval_mini_batch_size, embeddings_in_memory,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36m_evaluate_text_classifier\u001b[0;34m(model, sentences, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_labels_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mclear_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malso_clear_word_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0membeddings_in_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mforward_labels_and_loss\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_labels_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obtain_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtext_embedding_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m         \u001b[0;31m# first, sort sentences by number of tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;31m# get hidden states from language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mall_hidden_states_in_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_per_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# take first or last hidden states from language model as word representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mget_representation\u001b[0;34m(self, strings, chars_per_chunk)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, ordered_sequence_lengths)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train('./', max_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
